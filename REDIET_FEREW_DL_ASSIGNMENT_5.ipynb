{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Name: REDIET FEREW\n",
        "### ID No.: UGR/1415/12"
      ],
      "metadata": {
        "id": "XWPlCTLYN4S-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azrY-ynmaMbz"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dense Layer"
      ],
      "metadata": {
        "id": "ozdfRwjRMNA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DenseLayer():\n",
        "  def __init__(self, features, neurons):\n",
        "    self.weights = 0.01 * torch.rand(neurons, features)\n",
        "    self.biases = torch.zeros(1, neurons)\n",
        "  def forward(self, inputs):\n",
        "    self.inputs = inputs\n",
        "    self.output = torch.matmul(inputs, self.weights.T) + self.biases\n",
        "\n",
        "  def backward(self, dvalues):\n",
        "\n",
        "    self.dweights = torch.matmul(self.inputs.T, dvalues)\n",
        "    self.dbiases = torch.sum(dvalues, axis=0, keepdims=True)\n",
        "    self.dinputs = torch.matmul(dvalues, self.weights.T)\n"
      ],
      "metadata": {
        "id": "eDxCAS07aOcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ReLu Activation"
      ],
      "metadata": {
        "id": "SX72ZOqJMQJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Relu Activation Function\n",
        "\n",
        "class ActivationRelu:\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    #if inputs < 0 make 0 else make x\n",
        "    #tensor of some dimension\n",
        "    output = torch.max(inputs, torch.tensor(0.0))\n",
        "    return output\n",
        "  def backward(self, dvalues):\n",
        "\n",
        "    self.dinputs = dvalues.clone()\n",
        "\n",
        "    # The derivation of relu activation on the inputs\n",
        "    self.dinputs = self.dinputs[self.inputs <= 0] = 0\n",
        "\n"
      ],
      "metadata": {
        "id": "QDSRcdIfaQ7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Softmax Activation"
      ],
      "metadata": {
        "id": "OtmglnyCNhbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#softmax activation function\n",
        "class Activation_SoftMax:\n",
        "  def forward(self, inputs):\n",
        "    #calculate powers\n",
        "    power_x = torch.exp(inputs)\n",
        "    #get shape\n",
        "    shape_x = inputs.shape\n",
        "    sum_x = torch.sum(power_x, axis = 1, keepdims = True)\n",
        "    #divide\n",
        "    result = power_x / sum_x\n",
        "    self.output = result\n",
        "    return result\n",
        "  def backward(self, dvalues):\n",
        "    self.dinputs = torch.empty_like(dvalues)\n",
        "    for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
        "      single_output = single_output.reshape(-1, 1)\n",
        "      jacobian_matrix = torch.diagflat(single_output) - torch.dot(single_output, single_output.T)\n",
        "\n",
        "      self.dinputs[index] = torch.dot(jacobian_matrix, single_dvalues)"
      ],
      "metadata": {
        "id": "W6wTmTymaUIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nitialize activations\n",
        "relu = ActivationRelu()\n",
        "\n",
        "softmax = Activation_SoftMax()"
      ],
      "metadata": {
        "id": "z8o_wZ8pbgpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Forward Pass\n"
      ],
      "metadata": {
        "id": "qKhRSxape8qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "manual_seed = 42\n",
        "torch.manual_seed(manual_seed)\n",
        "\n",
        "# Number of features\n",
        "features = 2\n",
        "# Neurons in layers\n",
        "neuron_1 = 2\n",
        "# Output class\n",
        "output_class = 2\n",
        "# Number of samples\n",
        "samples = 10\n",
        "\n",
        "\n",
        "lower_bound = 0\n",
        "upper_bound = 10000\n",
        "input = (upper_bound - lower_bound) * torch.rand(samples, features) + lower_bound\n",
        "# input = torch.rand(samples, features)\n",
        "\n",
        "layer_1 = DenseLayer(features, neuron_1)\n",
        "layer_1.forward(input)\n",
        "output_1 = relu.forward(layer_1.output)\n",
        "print(output_1.shape)\n",
        "\n",
        "\n",
        "output_layer = DenseLayer(output_1.shape[1], output_class)\n",
        "output_layer.forward(output_1)\n",
        "print(output_layer.output.shape)\n",
        "final_output_1 = softmax.forward(output_layer.output)\n",
        "print(final_output_1)\n",
        "print(final_output_1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiWfvmwdcJpc",
        "outputId": "8eae9c22-6c44-4f46-d451-0cdb7d900378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "tensor([[0.4773, 0.5227],\n",
            "        [0.4826, 0.5174],\n",
            "        [0.4873, 0.5127],\n",
            "        [0.4863, 0.5137],\n",
            "        [0.4870, 0.5130],\n",
            "        [0.4810, 0.5190],\n",
            "        [0.4821, 0.5179],\n",
            "        [0.4854, 0.5146],\n",
            "        [0.4818, 0.5182],\n",
            "        [0.4884, 0.5116]])\n",
            "torch.Size([10, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Calculation"
      ],
      "metadata": {
        "id": "ZGiSReOkNmer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss:\n",
        "  def calculate(self, output, y):\n",
        "    sample_losses = self.forward(output, y)\n",
        "    data_loss = torch.mean(sample_losses)\n",
        "    return data_loss"
      ],
      "metadata": {
        "id": "ZLFPtjTgsh0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss_CategoricalCrossentropy(Loss):\n",
        "  def forward(self, y_pred, y_true):\n",
        "    samples = len(y_pred)\n",
        "\n",
        "    y_pred_clipped = torch.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "    if len(y_true.shape) == 1:\n",
        "      correct_confidences = y_pred_clipped[\n",
        "      range(samples),\n",
        "      y_true\n",
        "      ]\n",
        "    elif len(y_true.shape) == 2:\n",
        "      correct_confidences = torch.sum(\n",
        "      y_pred_clipped * y_true,\n",
        "      axis=1\n",
        "      )\n",
        "    negative_log_likelihoods = -torch.log(correct_confidences)\n",
        "    return negative_log_likelihoods\n",
        "  def backward(self, dvalues, y_true):\n",
        "    samples = len(dvalues)\n",
        "    labels = len(dvalues[0])\n",
        "    if len(y_true.shape) == 1:\n",
        "      y_true = torch.eye(labels)[y_true]\n",
        "    self.dinputs = -y_true / dvalues\n",
        "    self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NKPijlHonll1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
        "  def __init__(self):\n",
        "    self.activation = Activation_SoftMax()\n",
        "    self.loss = Loss_CategoricalCrossentropy()\n",
        "  def forward(self, inputs, y_true):\n",
        "    self.activation.forward(inputs)\n",
        "    self.output = self.activation.output\n",
        "    return self.loss.calculate(self.output, y_true)\n",
        "  def backward(self, dvalues, y_true):\n",
        "    samples = len(dvalues)\n",
        "    if len(y_true.shape) == 2:\n",
        "      y_true = torch.argmax(y_true, axis=1)\n",
        "    self.dinputs = dvalues.clone()\n",
        "    self.dinputs[range(samples), y_true] -= 1\n",
        "    self.dinputs = self.dinputs / samples\n"
      ],
      "metadata": {
        "id": "sgjQmxBgjvFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n"
      ],
      "metadata": {
        "id": "DmblvdPCrGaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = torch.randint(output_class, (samples,))"
      ],
      "metadata": {
        "id": "Ost-jOOBrbUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_activation.forward(final_output_1, target)\n"
      ],
      "metadata": {
        "id": "MD0CvjlBrSEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backward Propagation"
      ],
      "metadata": {
        "id": "vdoUTYy9NrfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss_activation.backward(loss_activation.output, target)\n",
        "layer_1.backward(loss_activation.dinputs)\n"
      ],
      "metadata": {
        "id": "1Q5WLDtuGP4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(layer_1.dweights)\n",
        "print(layer_1.dbiases)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Muxcq9zem0Yl",
        "outputId": "e7911831-a5dd-4b02-d643-a6b7c53a0dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1564.9775, -1564.9774],\n",
            "        [  594.1116,  -594.1115]])\n",
            "tensor([[ 0.0920, -0.0920]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qJdwYxOALO-2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}